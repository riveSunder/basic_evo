{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f653d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy gives us powerful linear algebra tools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(my_vector):\n",
    "    \n",
    "    return np.mean(my_vector)\n",
    "\n",
    "def max_ones(starting_vector, max_generations, threshold=0.9):\n",
    "\n",
    "    # best_vector = starting_vector\n",
    "    # ^^ note that simply assigning one vector to a new variable name does not make a new copy\n",
    "    best_vector = np.copy(starting_vector)\n",
    "    best_score = np.mean(best_vector)\n",
    "\n",
    "    # we'll do an evolutionary hill climb to get a vector of all ones\n",
    "    for generation in range(max_generations):\n",
    "\n",
    "        # the star in `*np.shape(best_vector)` unpacks the tuple containing the array shape\n",
    "        mutate_vector = np.random.rand(*np.shape(best_vector))\n",
    "\n",
    "        # this is another way to copy a vector. The result of the 1.0 * operation \n",
    "        # is returned, so we can safely modify temp_vector\n",
    "        temp_vector = 1.0 * best_vector\n",
    "\n",
    "        # mutate temp_vector by flipping the specified element to 1.0 \n",
    "        temp_vector[np.argmax(mutate_vector)] = 1.0\n",
    "\n",
    "        # the goal of this example is to get the highest mean value for all array elements\n",
    "        score = get_fitness(temp_vector)\n",
    "\n",
    "        # in a hill-climb, we replace the previous best with new best, or leave it alone. \n",
    "        if score > best_score:\n",
    "\n",
    "            best_vector = np.copy(temp_vector)\n",
    "            best_score = score\n",
    "\n",
    "        print(f\"generation {generation}, best score = {best_score:.3}\")\n",
    "\n",
    "    # in python, code is organized with white space (tabs and/or spaces)\n",
    "    # so we don't need  curly braces or 'end' lines. \n",
    "    return best_vector, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run it!\n",
    "\n",
    "starting_vector = np.zeros((32,))\n",
    "\n",
    "best_vector, best_score = max_ones(starting_vector, 100)\n",
    "\n",
    "print(f\"best score is {best_score} with the array: \")\n",
    "print(best_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fad30",
   "metadata": {},
   "source": [
    "Questions we can ask from here:\n",
    "\n",
    "* How many generations does it take (on average) before the vector is all ones? What if we change the number of elements?\n",
    "* At first the algorithm is likely to make an improvement (new best score) at every generation, but this slows down. How could we make the algorithm learn faster after it has already achieved a relatively high fitness?\n",
    "* ... ?\n",
    "\n",
    "* How can we modify the algorithm above to achieve an arbitrary target vector, instead of max ones? What if we don't restrict the vector values to just 0 and 1.0?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
